{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "495302cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a0cb4ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "002ea9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model   \n",
    "llm = init_chat_model(\"gpt-5-nano\", temperature=0.5, model_provider=\"openai\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1dbfa581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10f083e90>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcc70836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10f083e90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "026b68ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "861f9731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in workflow.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb555477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hi there! How can I assist you today? I can explain concepts, draft or edit text, help with coding, plan projects, summarize articles, translate, or just chat. What would you like to do?\n",
      "Assistant: LangChain is an open‑source framework that helps you build applications powered by large language models (LLMs). It provides a set of building blocks to orchestrate prompts, manage state, call tools, and create agents that can interact with external systems.\n",
      "\n",
      "Key ideas and components:\n",
      "- Prompts and templates: reusable, parameterized prompts.\n",
      "- Chains: sequences of steps (prompt calls, other chains, or tools) to produce an answer.\n",
      "- Agents and tools: LLMs that decide what actions to take (tools) and then perform them (e.g., search, calculator, file I/O, web API calls).\n",
      "- Memory: store and reuse past interactions to maintain context.\n",
      "- Vector stores: store and retrieve documents or knowledge for retrieval-augmented generation (e.g., FAISS, Pinecone, Milvus).\n",
      "- Multilanguage support: available for Python and JavaScript/TypeScript; works with various LLM providers (OpenAI, Azure, Hugging Face, etc.).\n",
      "\n",
      "Common use cases:\n",
      "- Chatbots and customer-support agents.\n",
      "- Question-answering systems over documents or knowledge bases.\n",
      "- Data analysis assistants that can run tools or code.\n",
      "- Automated agents that perform tasks by interacting with APIs or software.\n",
      "\n",
      "A tiny mental model:\n",
      "- You don’t write raw calls to an LLM anymore. You compose prompts, organize steps (chains), and optionally give the LLM access to tools (agents) to act in the real world.\n",
      "\n",
      "Quick-start vibe (high level):\n",
      "- Install LangChain, pick an LLM provider, define a prompt template, wrap it in a chain, and run it. You can later add memory, a retrieval layer, or an agent that uses tools.\n",
      "\n",
      "If you’d like, I can show a simple example (Python) or point you to the official docs to get you started.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efabeff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
